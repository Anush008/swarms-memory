{
    "agent_id": "a1f08173403d4f678a08904fa252f72d",
    "id": "989c00c78ccd4c4293c4c4d2c1133a6b",
    "llm": {
        "name": "OpenAIChatLLM",
        "doc": null
    },
    "template": null,
    "max_loops": 1,
    "stopping_condition": null,
    "loop_interval": 0,
    "retry_attempts": 1,
    "retry_interval": 1,
    "task": null,
    "stopping_token": "<DONE>",
    "interactive": false,
    "dashboard": false,
    "return_history": false,
    "dynamic_temperature_enabled": true,
    "dynamic_loops": false,
    "user_name": "swarms_corp",
    "context_length": 200000,
    "sop": null,
    "sop_list": null,
    "tools": null,
    "system_prompt": "Create a usage example for the following Python code: \n\n Return only python code.",
    "agent_name": "ExampleCreator",
    "agent_description": null,
    "saved_state_path": "ExampleCreator_state.json",
    "autosave": true,
    "response_filters": [],
    "self_healing_enabled": false,
    "code_interpreter": false,
    "multi_modal": null,
    "pdf_path": null,
    "list_of_pdf": null,
    "tokenizer": "<Non-serializable: TikTokenizer>",
    "long_term_memory": null,
    "preset_stopping_token": false,
    "traceback": null,
    "traceback_handlers": null,
    "streaming_on": false,
    "docs": null,
    "docs_folder": null,
    "verbose": true,
    "parser": null,
    "best_of_n": null,
    "callback": null,
    "metadata": null,
    "callbacks": null,
    "logger_handler": "<Non-serializable: TextIOWrapper>",
    "search_algorithm": null,
    "logs_to_filename": null,
    "evaluator": null,
    "output_json": false,
    "stopping_func": null,
    "custom_loop_condition": null,
    "sentiment_threshold": null,
    "custom_exit_command": "exit",
    "sentiment_analyzer": null,
    "limit_tokens_from_string": null,
    "tool_schema": null,
    "output_type": null,
    "function_calling_type": "json",
    "output_cleaner": null,
    "function_calling_format_type": "OpenAI",
    "list_base_models": null,
    "metadata_output_type": "json",
    "state_save_file_type": "json",
    "chain_of_thoughts": false,
    "algorithm_of_thoughts": false,
    "tree_of_thoughts": false,
    "tool_choice": "auto",
    "execute_tool": false,
    "planning": false,
    "planning_prompt": null,
    "device": null,
    "custom_planning_prompt": null,
    "rules": null,
    "custom_tools_prompt": null,
    "memory_chunk_size": 2000,
    "agent_ops_on": false,
    "log_directory": null,
    "tool_system_prompt": "\n\n\n    You've been granted tools to assist users by always providing outputs in JSON format for tool usage. \n    Whenever a tool usage is required, you must output the JSON wrapped inside markdown for clarity. \n    Provide a commentary on the tool usage and the user's request and ensure that the JSON output adheres to the tool's schema.\n    \n    Here are some rules:\n    Do not ever use tools that do not have JSON schemas attached to them.\n    Do not use tools that you have not been granted access to.\n    Do not use tools that are not relevant to the task at hand.\n    Do not use tools that are not relevant to the user's request.\n    \n    \n    Here are the guidelines you must follow:\n\n    1. **Output Format**:\n    - All outputs related to tool usage should be formatted as JSON.\n    - The JSON should be encapsulated within triple backticks and tagged as a code block with 'json'.\n\n    2. **Schema Compliance**:\n    - Ensure that the JSON output strictly follows the provided schema for each tool.\n    - Each tool's schema will define the structure and required fields for the JSON output.\n\n    3. **Schema Example**:\n    If a tool named `example_tool` with a schema requires `param1` and `param2`, your response should look like:\n    ```json\n    {\n        \"type\": \"function\",\n        \"function\": {\n        \"name\": \"example_tool\",\n        \"parameters\": {\n            \"param1\": 123,\n            \"param2\": \"example_value\"\n        }\n        }\n    }\n    ```\n\n    4. **Error Handling**:\n    - If there is an error or the information provided by the user is insufficient to generate a valid JSON, respond with an appropriate error message in JSON format, also encapsulated in markdown.\n\n    Remember, clarity and adherence to the schema are paramount. Your primary goal is to ensure the user receives well-structured JSON outputs that align with the tool's requirements.\n\n    ---\n\n    Here is the format you should always follow for your responses involving tool usage:\n\n    ```json\n    {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"<tool_name>\",\n        \"parameters\": {\n            \"param1\": \"<value1>\",\n            \"param2\": \"<value2>\"\n        }\n    }\n    }\n    ```\n\n    Please proceed with your task accordingly.\n\n    ",
    "max_tokens": 4096,
    "top_p": 0.9,
    "top_k": null,
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0,
    "temperature": 0.1,
    "workspace_dir": "agent_workspace",
    "timeout": null,
    "created_at": 1724877437.903637,
    "return_step_meta": false,
    "tags": null,
    "use_cases": null,
    "name": "ExampleCreator",
    "description": null,
    "reply": "",
    "question": null,
    "answer": "",
    "feedback": [],
    "short_memory": {
        "name": null,
        "description": null,
        "save_metadata_on": true,
        "save_artifact_path": "./artifacts",
        "save_metadata_path": "./metadata",
        "save_error_path": "./errors",
        "workspace_dir": "./workspace",
        "system_prompt": "Create a usage example for the following Python code: \n\n Return only python code.",
        "time_enabled": true,
        "autosave": false,
        "save_filepath": null,
        "conversation_history": [
            {
                "role": "System: ",
                "content": "Create a usage example for the following Python code: \n\n Return only python code.",
                "timestamp": "2024-08-28 16:37:18"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nimport uuid\nfrom typing import Any, List, Optional\n\nfrom sqlalchemy import JSON, Column, String, create_engine\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import Session\nfrom swarms_memory.dbs.base_db import AbstractDatabase\n\n\nclass PostgresDB(AbstractDatabase):\n    \"\"\"\n    A class representing a Postgres database.\n\n    Args:\n        connection_string (str): The connection string for the Postgres database.\n        table_name (str): The name of the table in the database.\n\n    Attributes:\n        engine: The SQLAlchemy engine for connecting to the database.\n        table_name (str): The name of the table in the database.\n        VectorModel: The SQLAlchemy model representing the vector table.\n\n    \"\"\"\n\n    def __init__(\n        self, connection_string: str, table_name: str, *args, **kwargs\n    ):\n        \"\"\"\n        Initializes a new instance of the PostgresDB class.\n\n        Args:\n            connection_string (str): The connection string for the Postgres database.\n            table_name (str): The name of the table in the database.\n\n        \"\"\"\n        self.engine = create_engine(\n            connection_string, *args, **kwargs\n        )\n        self.table_name = table_name\n        self.VectorModel = self._create_vector_model()\n\n    def _create_vector_model(self):\n        \"\"\"\n        Creates the SQLAlchemy model for the vector table.\n\n        Returns:\n            The SQLAlchemy model representing the vector table.\n\n        \"\"\"\n        Base = declarative_base()\n\n        class VectorModel(Base):\n            __tablename__ = self.table_name\n\n            id = Column(\n                UUID(as_uuid=True),\n                primary_key=True,\n                default=uuid.uuid4,\n                unique=True,\n                nullable=False,\n            )\n            vector = Column(\n                String\n            )  # Assuming vector is stored as a string\n            namespace = Column(String)\n            meta = Column(JSON)\n\n        return VectorModel\n\n    def add(\n        self,\n        vector: str,\n        vector_id: Optional[str] = None,\n        namespace: Optional[str] = None,\n        meta: Optional[dict] = None,\n    ) -> None:\n        \"\"\"\n        Adds or updates a vector in the database.\n\n        Args:\n            vector (str): The vector to be added or updated.\n            vector_id (str, optional): The ID of the vector. If not provided, a new ID will be generated.\n            namespace (str, optional): The namespace of the vector.\n            meta (dict, optional): Additional metadata associated with the vector.\n\n        \"\"\"\n        try:\n            with Session(self.engine) as session:\n                obj = self.VectorModel(\n                    id=vector_id,\n                    vector=vector,\n                    namespace=namespace,\n                    meta=meta,\n                )\n                session.merge(obj)\n                session.commit()\n        except Exception as e:\n            print(f\"Error adding or updating vector: {e}\")\n\n    def query(\n        self, query: Any, namespace: Optional[str] = None\n    ) -> List[Any]:\n        \"\"\"\n        Queries vectors from the database based on the given query and namespace.\n\n        Args:\n            query (Any): The query or condition to filter the vectors.\n            namespace (str, optional): The namespace of the vectors to be queried.\n\n        Returns:\n            List[Any]: A list of vectors that match the query and namespace.\n\n        \"\"\"\n        try:\n            with Session(self.engine) as session:\n                q = session.query(self.VectorModel)\n                if namespace:\n                    q = q.filter_by(namespace=namespace)\n                # Assuming 'query' is a condition or filter\n                q = q.filter(query)\n                return q.all()\n        except Exception as e:\n            print(f\"Error querying vectors: {e}\")\n            return []\n\n    def delete_vector(self, vector_id):\n        \"\"\"\n        Deletes a vector from the database based on the given vector ID.\n\n        Args:\n            vector_id: The ID of the vector to be deleted.\n\n        \"\"\"\n        try:\n            with Session(self.engine) as session:\n                obj = session.get(self.VectorModel, vector_id)\n                if obj:\n                    session.delete(obj)\n                    session.commit()\n        except Exception as e:\n            print(f\"Error deleting vector: {e}\")\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:18"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the PostgresDB class\n\n# Import necessary libraries\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\n# Define the connection string for the PostgreSQL database\nconnection_string = \"postgresql://user:password@localhost/mydatabase\"\n\n# Define the table name where vectors will be stored\ntable_name = \"vectors_table\"\n\n# Create an instance of the PostgresDB class\ndb = PostgresDB(connection_string, table_name)\n\n# Add a new vector to the database\nvector_data = \"1.0, 2.0, 3.0\"  # Example vector as a string\ndb.add(vector=vector_data, namespace=\"example_namespace\", meta={\"source\": \"test\"})\n\n# Query vectors from the database\nfrom sqlalchemy import and_\n\n# Create a query condition (e.g., filter by a specific namespace)\nquery_condition = and_(db.VectorModel.vector.like(\"1.0%\"))  # Example condition\nresults = db.query(query=query_condition, namespace=\"example_namespace\")\n\n# Print the results of the query\nfor result in results:\n    print(f\"ID: {result.id}, Vector: {result.vector}, Namespace: {result.namespace}, Meta: {result.meta}\")\n\n# Delete a vector from the database by its ID\n# Assuming we have the ID of the vector we want to delete\nvector_id_to_delete = results[0].id if results else None  # Get the first result's ID\nif vector_id_to_delete:\n    db.delete_vector(vector_id_to_delete)\n    print(f\"Deleted vector with ID: {vector_id_to_delete}\")\nelse:\n    print(\"No vector found to delete.\")\n```",
                "timestamp": "2024-08-28 16:37:23"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom typing import Any, List, Optional, Tuple\n\nfrom swarms_memory.dbs.base_db import AbstractDatabase\n\ntry:\n    import sqlite3\nexcept ImportError:\n    raise ImportError(\n        \"Please install sqlite3 to use the SQLiteDB class.\"\n    )\n\n\nclass SQLiteDB(AbstractDatabase):\n    \"\"\"\n    A reusable class for SQLite database operations with methods for adding,\n    deleting, updating, and querying data.\n\n    Attributes:\n        db_path (str): The file path to the SQLite database.\n    \"\"\"\n\n    def __init__(self, db_path: str):\n        \"\"\"\n        Initializes the SQLiteDB class with the given database path.\n\n        Args:\n            db_path (str): The file path to the SQLite database.\n        \"\"\"\n        self.db_path = db_path\n\n    def execute_query(\n        self, query: str, params: Optional[Tuple[Any, ...]] = None\n    ) -> List[Tuple]:\n        \"\"\"\n        Executes a SQL query and returns fetched results.\n\n        Args:\n            query (str): The SQL query to execute.\n            params (Tuple[Any, ...], optional): The parameters to substitute into the query.\n\n        Returns:\n            List[Tuple]: The results fetched from the database.\n        \"\"\"\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query, params or ())\n                return cursor.fetchall()\n        except Exception as error:\n            print(f\"Error executing query: {error}\")\n            raise error\n\n    def add(self, query: str, params: Tuple[Any, ...]) -> None:\n        \"\"\"\n        Adds a new entry to the database.\n\n        Args:\n            query (str): The SQL query for insertion.\n            params (Tuple[Any, ...]): The parameters to substitute into the query.\n        \"\"\"\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query, params)\n                conn.commit()\n        except Exception as error:\n            print(f\"Error adding new entry: {error}\")\n            raise error\n\n    def delete(self, query: str, params: Tuple[Any, ...]) -> None:\n        \"\"\"\n        Deletes an entry from the database.\n\n        Args:\n            query (str): The SQL query for deletion.\n            params (Tuple[Any, ...]): The parameters to substitute into the query.\n        \"\"\"\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query, params)\n                conn.commit()\n        except Exception as error:\n            print(f\"Error deleting entry: {error}\")\n            raise error\n\n    def update(self, query: str, params: Tuple[Any, ...]) -> None:\n        \"\"\"\n        Updates an entry in the database.\n\n        Args:\n            query (str): The SQL query for updating.\n            params (Tuple[Any, ...]): The parameters to substitute into the query.\n        \"\"\"\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query, params)\n                conn.commit()\n        except Exception as error:\n            print(f\"Error updating entry: {error}\")\n            raise error\n\n    def query(\n        self, query: str, params: Optional[Tuple[Any, ...]] = None\n    ) -> List[Tuple]:\n        \"\"\"\n        Fetches data from the database based on a query.\n\n        Args:\n            query (str): The SQL query to execute.\n            params (Tuple[Any, ...], optional): The parameters to substitute into the query.\n\n        Returns:\n            List[Tuple]: The results fetched from the database.\n        \"\"\"\n        try:\n            return self.execute_query(query, params)\n        except Exception as error:\n            print(f\"Error querying database: {error}\")\n            raise error\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:23"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the SQLiteDB class\n\n# Define the path to the SQLite database file\ndb_path = \"example_database.db\"\n\n# Create an instance of the SQLiteDB class\ndb = SQLiteDB(db_path)\n\n# Create a table for storing example data (if it doesn't already exist)\ncreate_table_query = \"\"\"\nCREATE TABLE IF NOT EXISTS example_table (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    name TEXT NOT NULL,\n    age INTEGER NOT NULL\n);\n\"\"\"\ndb.execute_query(create_table_query)\n\n# Add a new entry to the database\ninsert_query = \"INSERT INTO example_table (name, age) VALUES (?, ?)\"\ndb.add(insert_query, (\"Alice\", 30))\n\n# Add another entry to the database\ndb.add(insert_query, (\"Bob\", 25))\n\n# Query the database to retrieve all entries\nselect_query = \"SELECT * FROM example_table\"\nresults = db.query(select_query)\n\n# Print the results of the query\nprint(\"Entries in the database:\")\nfor result in results:\n    print(f\"ID: {result[0]}, Name: {result[1]}, Age: {result[2]}\")\n\n# Update an entry in the database\nupdate_query = \"UPDATE example_table SET age = ? WHERE name = ?\"\ndb.update(update_query, (31, \"Alice\"))\n\n# Query the database again to see the updated entry\nresults = db.query(select_query)\nprint(\"\\nEntries after update:\")\nfor result in results:\n    print(f\"ID: {result[0]}, Name: {result[1]}, Age: {result[2]}\")\n\n# Delete an entry from the database\ndelete_query = \"DELETE FROM example_table WHERE name = ?\"\ndb.delete(delete_query, (\"Bob\",))\n\n# Query the database to see the remaining entries\nresults = db.query(select_query)\nprint(\"\\nEntries after deletion:\")\nfor result in results:\n    print(f\"ID: {result[0]}, Name: {result[1]}, Age: {result[2]}\")\n```",
                "timestamp": "2024-08-28 16:37:28"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom abc import ABC, abstractmethod\n\n\nclass AbstractDatabase(ABC):\n    \"\"\"\n    Abstract base class for a database.\n\n    This class defines the interface for interacting with a database.\n    Subclasses must implement the abstract methods to provide the\n    specific implementation details for connecting to a database,\n    executing queries, and performing CRUD operations.\n\n    \"\"\"\n\n    @abstractmethod\n    def connect(self):\n        \"\"\"\n        Connect to the database.\n\n        This method establishes a connection to the database.\n\n        \"\"\"\n\n    @abstractmethod\n    def close(self):\n        \"\"\"\n        Close the database connection.\n\n        This method closes the connection to the database.\n\n        \"\"\"\n\n    @abstractmethod\n    def execute_query(self, query):\n        \"\"\"\n        Execute a database query.\n\n        This method executes the given query on the database.\n\n        Parameters:\n            query (str): The query to be executed.\n\n        \"\"\"\n\n    @abstractmethod\n    def fetch_all(self):\n        \"\"\"\n        Fetch all rows from the result set.\n\n        This method retrieves all rows from the result set of a query.\n\n        Returns:\n            list: A list of dictionaries representing the rows.\n\n        \"\"\"\n\n    @abstractmethod\n    def fetch_one(self):\n        \"\"\"\n        Fetch one row from the result set.\n\n        This method retrieves one row from the result set of a query.\n\n        Returns:\n            dict: A dictionary representing the row.\n\n        \"\"\"\n\n    @abstractmethod\n    def add(self, table, data):\n        \"\"\"\n        Add a new record to the database.\n\n        This method adds a new record to the specified table in the database.\n\n        Parameters:\n            table (str): The name of the table.\n            data (dict): A dictionary representing the data to be added.\n\n        \"\"\"\n\n    @abstractmethod\n    def query(self, table, condition):\n        \"\"\"\n        Query the database.\n\n        This method queries the specified table in the database based on the given condition.\n\n        Parameters:\n            table (str): The name of the table.\n            condition (str): The condition to be applied in the query.\n\n        Returns:\n            list: A list of dictionaries representing the query results.\n\n        \"\"\"\n\n    @abstractmethod\n    def get(self, table, id):\n        \"\"\"\n        Get a record from the database.\n\n        This method retrieves a record from the specified table in the database based on the given ID.\n\n        Parameters:\n            table (str): The name of the table.\n            id (int): The ID of the record to be retrieved.\n\n        Returns:\n            dict: A dictionary representing the retrieved record.\n\n        \"\"\"\n\n    @abstractmethod\n    def update(self, table, id, data):\n        \"\"\"\n        Update a record in the database.\n\n        This method updates a record in the specified table in the database based on the given ID.\n\n        Parameters:\n            table (str): The name of the table.\n            id (int): The ID of the record to be updated.\n            data (dict): A dictionary representing the updated data.\n\n        \"\"\"\n\n    @abstractmethod\n    def delete(self, table, id):\n        \"\"\"\n        Delete a record from the database.\n\n        This method deletes a record from the specified table in the database based on the given ID.\n\n        Parameters:\n            table (str): The name of the table.\n            id (int): The ID of the record to be deleted.\n\n        \"\"\"\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:28"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the AbstractDatabase class\n\n# First, we need to create a concrete implementation of the AbstractDatabase class\n# Let's create a simple in-memory SQLite database as an example.\n\nimport sqlite3\n\nclass SQLiteDatabase(AbstractDatabase):\n    \"\"\"\n    Concrete implementation of the AbstractDatabase for SQLite.\n    \"\"\"\n\n    def __init__(self):\n        self.connection = None\n\n    def connect(self):\n        \"\"\"Establishes a connection to the SQLite database.\"\"\"\n        self.connection = sqlite3.connect(':memory:')  # Using an in-memory database for demonstration\n        self.create_table()\n\n    def close(self):\n        \"\"\"Closes the database connection.\"\"\"\n        if self.connection:\n            self.connection.close()\n\n    def create_table(self):\n        \"\"\"Creates a sample table for demonstration purposes.\"\"\"\n        with self.connection:\n            self.connection.execute(\"\"\"\n            CREATE TABLE users (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                name TEXT NOT NULL,\n                age INTEGER NOT NULL\n            )\n            \"\"\")\n\n    def execute_query(self, query):\n        \"\"\"Executes a database query.\"\"\"\n        with self.connection:\n            return self.connection.execute(query)\n\n    def fetch_all(self):\n        \"\"\"Fetches all rows from the result set.\"\"\"\n        return self.connection.fetchall()\n\n    def fetch_one(self):\n        \"\"\"Fetches one row from the result set.\"\"\"\n        return self.connection.fetchone()\n\n    def add(self, table, data):\n        \"\"\"Adds a new record to the database.\"\"\"\n        columns = ', '.join(data.keys())\n        placeholders = ', '.join(['?'] * len(data))\n        query = f\"INSERT INTO {table} ({columns}) VALUES ({placeholders})\"\n        with self.connection:\n            self.connection.execute(query, tuple(data.values()))\n\n    def query(self, table, condition):\n        \"\"\"Queries the database based on the given condition.\"\"\"\n        query = f\"SELECT * FROM {table} WHERE {condition}\"\n        self.execute_query(query)\n        return self.fetch_all()\n\n    def get(self, table, id):\n        \"\"\"Retrieves a record from the database based on the given ID.\"\"\"\n        query = f\"SELECT * FROM {table} WHERE id = ?\"\n        self.execute_query(query, (id,))\n        return self.fetch_one()\n\n    def update(self, table, id, data):\n        \"\"\"Updates a record in the database based on the given ID.\"\"\"\n        set_clause = ', '.join([f\"{key} = ?\" for key in data.keys()])\n        query = f\"UPDATE {table} SET {set_clause} WHERE id = ?\"\n        with self.connection:\n            self.connection.execute(query, (*data.values(), id))\n\n    def delete(self, table, id):\n        \"\"\"Deletes a record from the database based on the given ID.\"\"\"\n        query = f\"DELETE FROM {table} WHERE id = ?\"\n        with self.connection:\n            self.connection.execute(query, (id,))\n\n# Example usage of the SQLiteDatabase class\ndb = SQLiteDatabase()\ndb.connect()\n\n# Adding new users to the database\ndb.add('users', {'name': 'Alice', 'age': 30})\ndb.add('users', {'name': 'Bob', 'age': 25})\n\n# Querying users from the database\nusers = db.query('users', 'age > 20')\nprint(\"Users older than 20:\")\nfor user in users:\n    print(f\"ID: {user[0]}, Name: {user[1]}, Age: {user[2]}\")\n\n# Updating a user\ndb.update('users', 1, {'age': 31})  # Update Alice's age to 31\n\n# Fetching a specific user\nuser = db.get('users', 1)\nprint(f\"\\nUpdated User: ID: {user[0]}, Name: {user[1]}, Age: {user[2]}\")\n\n# Deleting a user\ndb.delete('users', 2)  # Delete Bob\n\n# Querying again to see remaining users\nremaining_users = db.query('users', '1=1')  # Get all users\nprint(\"\\nRemaining Users:\")\nfor user in remaining_users:\n    print(f\"ID: {user[0]}, Name: {user[1]}, Age: {user[2]}\")\n\n# Closing the database connection\ndb.close()\n```",
                "timestamp": "2024-08-28 16:37:38"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nimport datetime\nimport json\nimport os\nimport threading\nimport uuid\nfrom pathlib import Path\nfrom typing import Any, Dict\n\n\nclass DictSharedMemory:\n    \"\"\"A class representing a shared memory that stores entries as a dictionary.\n\n    Attributes:\n        file_loc (Path): The file location where the memory is stored.\n        lock (threading.Lock): A lock used for thread synchronization.\n\n    Methods:\n        __init__(self, file_loc: str = None) -> None: Initializes the shared memory.\n        add_entry(self, score: float, agent_id: str, agent_cycle: int, entry: Any) -> bool: Adds an entry to the internal memory.\n        get_top_n(self, n: int) -> None: Gets the top n entries from the internal memory.\n        write_to_file(self, data: Dict[str, Dict[str, Any]]) -> bool: Writes the internal memory to a file.\n    \"\"\"\n\n    def __init__(self, file_loc: str = None) -> None:\n        \"\"\"Initialize the shared memory. In the current architecture the memory always consists of a set of soltuions or evaluations.\n        Moreover, the project is designed around LLMs for the proof of concepts, so we treat all entry content as a string.\n        \"\"\"\n        if file_loc is not None:\n            self.file_loc = Path(file_loc)\n            if not self.file_loc.exists():\n                self.file_loc.touch()\n\n        self.lock = threading.Lock()\n\n    def add(\n        self,\n        score: float,\n        agent_id: str,\n        agent_cycle: int,\n        entry: Any,\n    ) -> bool:\n        \"\"\"Add an entry to the internal memory.\"\"\"\n        with self.lock:\n            entry_id = str(uuid.uuid4())\n            data = {}\n            epoch = datetime.datetime.utcfromtimestamp(0)\n            epoch = (\n                datetime.datetime.utcnow() - epoch\n            ).total_seconds()\n            data[entry_id] = {\n                \"agent\": agent_id,\n                \"epoch\": epoch,\n                \"score\": score,\n                \"cycle\": agent_cycle,\n                \"content\": entry,\n            }\n            status = self.write_to_file(data)\n            self.plot_performance()\n            return status\n\n    def get_top_n(self, n: int) -> None:\n        \"\"\"Get the top n entries from the internal memory.\"\"\"\n        with self.lock:\n            with open(self.file_loc) as f:\n                try:\n                    file_data = json.load(f)\n                except Exception as e:\n                    file_data = {}\n                    raise e\n\n            sorted_data = dict(\n                sorted(\n                    file_data.items(),\n                    key=lambda item: item[1][\"score\"],\n                    reverse=True,\n                )\n            )\n            top_n = dict(list(sorted_data.items())[:n])\n            return top_n\n\n    def write_to_file(self, data: Dict[str, Dict[str, Any]]) -> bool:\n        \"\"\"Write the internal memory to a file.\"\"\"\n        if self.file_loc is not None:\n            with open(self.file_loc) as f:\n                try:\n                    file_data = json.load(f)\n                except Exception as e:\n                    file_data = {}\n                    raise e\n\n            file_data = file_data | data\n            with open(self.file_loc, \"w\") as f:\n                json.dump(file_data, f, indent=4)\n\n                f.flush()\n                os.fsync(f.fileno())\n\n            return True\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:38"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the DictSharedMemory class\n\n# Import necessary libraries\nimport time\n\n# Define the file location where the shared memory will be stored\nfile_location = \"shared_memory.json\"\n\n# Create an instance of the DictSharedMemory class\nshared_memory = DictSharedMemory(file_loc=file_location)\n\n# Function to simulate adding entries to shared memory\ndef add_entries(agent_id, cycles):\n    for cycle in range(cycles):\n        score = cycle * 10.0  # Example score based on cycle\n        entry_content = f\"Entry from agent {agent_id} at cycle {cycle}\"\n        shared_memory.add(score=score, agent_id=agent_id, agent_cycle=cycle, entry=entry_content)\n        time.sleep(1)  # Simulate some delay\n\n# Start multiple threads to add entries concurrently\nthread1 = threading.Thread(target=add_entries, args=(\"Agent_1\", 5))\nthread2 = threading.Thread(target=add_entries, args=(\"Agent_2\", 5))\n\nthread1.start()\nthread2.start()\n\n# Wait for both threads to finish\nthread1.join()\nthread2.join()\n\n# Retrieve the top 3 entries from the shared memory\ntop_entries = shared_memory.get_top_n(n=3)\n\n# Print the top entries\nprint(\"Top 3 entries in shared memory:\")\nfor entry_id, entry_data in top_entries.items():\n    print(f\"ID: {entry_id}, Agent: {entry_data['agent']}, Score: {entry_data['score']}, Cycle: {entry_data['cycle']}, Content: {entry_data['content']}\")\n\n# At this point, the shared memory file 'shared_memory.json' will contain all the entries added\n```",
                "timestamp": "2024-08-28 16:37:42"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom datetime import datetime\nfrom typing import List\n\n\nclass VisualShortTermMemory:\n    \"\"\"\n    A class representing visual short-term memory.\n\n    Attributes:\n        memory (list): A list to store images and their descriptions.\n\n    Examples:\n        example = VisualShortTermMemory()\n        example.add(\n            images=[\"image1.jpg\", \"image2.jpg\"],\n            description=[\"description1\", \"description2\"],\n            timestamps=[1.0, 2.0],\n            locations=[\"location1\", \"location2\"],\n        )\n        print(example.return_as_string())\n        # print(example.get_images())\n    \"\"\"\n\n    def __init__(self):\n        self.memory = []\n\n    def add(\n        self,\n        images: List[str] = None,\n        description: List[str] = None,\n        timestamps: List[float] = None,\n        locations: List[str] = None,\n    ):\n        \"\"\"\n        Add images and their descriptions to the memory.\n\n        Args:\n            images (list): A list of image paths.\n            description (list): A list of corresponding descriptions.\n            timestamps (list): A list of timestamps for each image.\n            locations (list): A list of locations where the images were captured.\n        \"\"\"\n        current_time = datetime.now()\n\n        # Create a dictionary of each image and description\n        # and append it to the memory\n        for image, description, timestamp, location in zip(\n            images, description, timestamps, locations\n        ):\n            self.memory.append(\n                {\n                    \"image\": image,\n                    \"description\": description,\n                    \"timestamp\": timestamp,\n                    \"location\": location,\n                    \"added_at\": current_time,\n                }\n            )\n\n    def get_images(self):\n        \"\"\"\n        Get a list of all images in the memory.\n\n        Returns:\n            list: A list of image paths.\n        \"\"\"\n        return [item[\"image\"] for item in self.memory]\n\n    def get_descriptions(self):\n        \"\"\"\n        Get a list of all descriptions in the memory.\n\n        Returns:\n            list: A list of descriptions.\n        \"\"\"\n        return [item[\"description\"] for item in self.memory]\n\n    def search_by_location(self, location: str):\n        \"\"\"\n        Search for images captured at a specific location.\n\n        Args:\n            location (str): The location to search for.\n\n        Returns:\n            list: A list of images captured at the specified location.\n        \"\"\"\n        return [\n            item[\"image\"]\n            for item in self.memory\n            if item[\"location\"] == location\n        ]\n\n    def search_by_timestamp(self, start_time: float, end_time: float):\n        \"\"\"\n        Search for images captured within a specific time range.\n\n        Args:\n            start_time (float): The start time of the range.\n            end_time (float): The end time of the range.\n\n        Returns:\n            list: A list of images captured within the specified time range.\n        \"\"\"\n        return [\n            item[\"image\"]\n            for item in self.memory\n            if start_time <= item[\"timestamp\"] <= end_time\n        ]\n\n    def return_as_string(self):\n        \"\"\"\n        Return the memory as a string.\n\n        Returns:\n            str: A string representation of the memory.\n        \"\"\"\n        return str(self.memory)\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:42"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the VisualShortTermMemory class\n\n# Import necessary libraries\nfrom datetime import datetime\n\n# Create an instance of the VisualShortTermMemory class\nvisual_memory = VisualShortTermMemory()\n\n# Define some example images, descriptions, timestamps, and locations\nimages = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\ndescriptions = [\"A beautiful sunset\", \"A busy street\", \"A calm beach\"]\ntimestamps = [datetime.now().timestamp(), datetime.now().timestamp() + 1, datetime.now().timestamp() + 2]\nlocations = [\"Beach\", \"City\", \"Beach\"]\n\n# Add the images and their details to the visual memory\nvisual_memory.add(images=images, description=descriptions, timestamps=timestamps, locations=locations)\n\n# Retrieve and print all images stored in memory\nstored_images = visual_memory.get_images()\nprint(\"Stored Images:\", stored_images)\n\n# Retrieve and print all descriptions stored in memory\nstored_descriptions = visual_memory.get_descriptions()\nprint(\"Stored Descriptions:\", stored_descriptions)\n\n# Search for images captured at a specific location\nlocation_search = \"Beach\"\nimages_at_location = visual_memory.search_by_location(location=location_search)\nprint(f\"Images captured at {location_search}:\", images_at_location)\n\n# Search for images captured within a specific time range\n# Assuming we want to search for images added in the last 2 seconds\nstart_time = datetime.now().timestamp() - 3  # 3 seconds ago\nend_time = datetime.now().timestamp() + 3    # 3 seconds from now\nimages_in_time_range = visual_memory.search_by_timestamp(start_time=start_time, end_time=end_time)\nprint(\"Images captured in the last 2 seconds:\", images_in_time_range)\n\n# Print the entire memory as a string representation\nmemory_string = visual_memory.return_as_string()\nprint(\"Memory as string:\", memory_string)\n```",
                "timestamp": "2024-08-28 16:37:47"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nimport json\nimport logging\nimport threading\n\n\nclass ShortTermMemory:\n    \"\"\"Short term memory.\n\n    Args:\n    return_str (bool, optional): _description_. Defaults to True.\n    autosave (bool, optional): _description_. Defaults to True.\n    *args: _description_\n    **kwargs: _description_\n\n\n    Example:\n    >>> from swarms_memory.short_term_memory import ShortTermMemory\n    >>> stm = ShortTermMemory()\n    >>> stm.add(role=\"agent\", message=\"Hello world!\")\n    >>> stm.add(role=\"agent\", message=\"How are you?\")\n    >>> stm.add(role=\"agent\", message=\"I am fine.\")\n    >>> stm.add(role=\"agent\", message=\"How are you?\")\n    >>> stm.add(role=\"agent\", message=\"I am fine.\")\n\n\n    \"\"\"\n\n    def __init__(\n        self,\n        return_str: bool = True,\n        autosave: bool = True,\n        *args,\n        **kwargs,\n    ):\n        self.return_str = return_str\n        self.autosave = autosave\n        self.short_term_memory = []\n        self.medium_term_memory = []\n        self.lock = threading.Lock()\n\n    def add(\n        self, role: str = None, message: str = None, *args, **kwargs\n    ):\n        \"\"\"Add a message to the short term memory.\n\n        Args:\n            role (str, optional): _description_. Defaults to None.\n            message (str, optional): _description_. Defaults to None.\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        try:\n            memory = self.short_term_memory.append(\n                {\"role\": role, \"message\": message}\n            )\n\n            return memory\n        except Exception as error:\n            print(f\"Add to short term memory failed: {error}\")\n            raise error\n\n    def get_short_term(self):\n        \"\"\"Get the short term memory.\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        return self.short_term_memory\n\n    def get_medium_term(self):\n        \"\"\"Get the medium term memory.\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        return self.medium_term_memory\n\n    def clear_medium_term(self):\n        \"\"\"Clear the medium term memory.\"\"\"\n        self.medium_term_memory = []\n\n    def get_short_term_memory_str(self, *args, **kwargs):\n        \"\"\"Get the short term memory as a string.\"\"\"\n        return str(self.short_term_memory)\n\n    def update_short_term(\n        self, index, role: str, message: str, *args, **kwargs\n    ):\n        \"\"\"Update the short term memory.\n\n        Args:\n            index (_type_): _description_\n            role (str): _description_\n            message (str): _description_\n\n        \"\"\"\n        self.short_term_memory[index] = {\n            \"role\": role,\n            \"message\": message,\n        }\n\n    def clear(self):\n        \"\"\"Clear the short term memory.\"\"\"\n        self.short_term_memory = []\n\n    def search_memory(self, term):\n        \"\"\"Search the memory for a term.\n\n        Args:\n            term (_type_): _description_\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        results = {\"short_term\": [], \"medium_term\": []}\n        for i, message in enumerate(self.short_term_memory):\n            if term in message[\"message\"]:\n                results[\"short_term\"].append((i, message))\n        for i, message in enumerate(self.medium_term_memory):\n            if term in message[\"message\"]:\n                results[\"medium_term\"].append((i, message))\n        return results\n\n    def return_shortmemory_as_str(self):\n        \"\"\"Return the memory as a string.\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        return str(self.short_term_memory)\n\n    def move_to_medium_term(self, index):\n        \"\"\"Move a message from the short term memory to the medium term memory.\n\n        Args:\n            index (_type_): _description_\n        \"\"\"\n        message = self.short_term_memory.pop(index)\n        self.medium_term_memory.append(message)\n\n    def return_medium_memory_as_str(self):\n        \"\"\"Return the medium term memory as a string.\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        return str(self.medium_term_memory)\n\n    def save_to_file(self, filename: str):\n        \"\"\"Save the memory to a file.\n\n        Args:\n            filename (str): _description_\n        \"\"\"\n        try:\n            with self.lock:\n                with open(filename, \"w\") as f:\n                    json.dump(\n                        {\n                            \"short_term_memory\": (\n                                self.short_term_memory\n                            ),\n                            \"medium_term_memory\": (\n                                self.medium_term_memory\n                            ),\n                        },\n                        f,\n                    )\n\n                    logging.info(f\"Saved memory to {filename}\")\n        except Exception as error:\n            print(f\"Error saving memory to {filename}: {error}\")\n\n    def load_from_file(self, filename: str, *args, **kwargs):\n        \"\"\"Load the memory from a file.\n\n        Args:\n            filename (str): _description_\n        \"\"\"\n        try:\n            with self.lock:\n                with open(filename) as f:\n                    data = json.load(f)\n                self.short_term_memory = data.get(\n                    \"short_term_memory\", []\n                )\n                self.medium_term_memory = data.get(\n                    \"medium_term_memory\", []\n                )\n                logging.info(f\"Loaded memory from {filename}\")\n        except Exception as error:\n            print(f\"Erorr loading memory from {filename}: {error}\")\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:47"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the ShortTermMemory class\n\n# Import necessary libraries\nimport time\n\n# Create an instance of the ShortTermMemory class\nstm = ShortTermMemory()\n\n# Add messages to the short term memory\nstm.add(role=\"agent\", message=\"Hello world!\")\nstm.add(role=\"agent\", message=\"How are you?\")\nstm.add(role=\"agent\", message=\"I am fine.\")\nstm.add(role=\"agent\", message=\"What about you?\")\nstm.add(role=\"agent\", message=\"I am doing well, thank you!\")\n\n# Retrieve and print the short term memory\nshort_term_memory = stm.get_short_term()\nprint(\"Short Term Memory:\")\nfor entry in short_term_memory:\n    print(f\"Role: {entry['role']}, Message: {entry['message']}\")\n\n# Search for a specific term in the memory\nsearch_term = \"fine\"\nsearch_results = stm.search_memory(search_term)\nprint(f\"\\nSearch results for term '{search_term}':\")\nprint(\"Short Term Results:\", search_results[\"short_term\"])\nprint(\"Medium Term Results:\", search_results[\"medium_term\"])\n\n# Move the first message from short term to medium term memory\nif short_term_memory:\n    stm.move_to_medium_term(0)\n\n# Retrieve and print the medium term memory\nmedium_term_memory = stm.get_medium_term()\nprint(\"\\nMedium Term Memory:\")\nfor entry in medium_term_memory:\n    print(f\"Role: {entry['role']}, Message: {entry['message']}\")\n\n# Save the current memory to a file\nfilename = \"memory.json\"\nstm.save_to_file(filename)\n\n# Clear the short term memory\nstm.clear()\n\n# Load the memory back from the file\nstm.load_from_file(filename)\n\n# Print the loaded short term memory\nloaded_short_term_memory = stm.get_short_term()\nprint(\"\\nLoaded Short Term Memory from file:\")\nfor entry in loaded_short_term_memory:\n    print(f\"Role: {entry['role']}, Message: {entry['message']}\")\n\n# Clear the medium term memory\nstm.clear_medium_term()\n\n# Print the medium term memory after clearing\nprint(\"\\nMedium Term Memory after clearing:\")\nprint(stm.return_medium_memory_as_str())\n```",
                "timestamp": "2024-08-28 16:37:56"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Tuple\n\n\nclass InternalMemoryBase(ABC):\n    \"\"\"Abstract base class for internal memory of agents in the swarm.\"\"\"\n\n    def __init__(self, n_entries):\n        \"\"\"Initialize the internal memory. In the current architecture the memory always consists of a set of soltuions or evaluations.\n        During the operation, the agent should retrivie best solutions from it's internal memory based on the score.\n\n        Moreover, the project is designed around LLMs for the proof of concepts, so we treat all entry content as a string.\n        \"\"\"\n        self.n_entries = n_entries\n\n    @abstractmethod\n    def add(self, score, entry):\n        \"\"\"Add an entry to the internal memory.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_top_n(self, n):\n        \"\"\"Get the top n entries from the internal memory.\"\"\"\n        raise NotImplementedError\n\n\nclass DictInternalMemory(InternalMemoryBase):\n    def __init__(self, n_entries: int):\n        \"\"\"\n        Initialize the internal memory. In the current architecture the memory always consists of a set of solutions or evaluations.\n        Simple key-value store for now.\n\n        Args:\n            n_entries (int): The maximum number of entries to keep in the internal memory.\n        \"\"\"\n        super().__init__(n_entries)\n        self.data: Dict[str, Dict[str, Any]] = {}\n\n    def add(self, score: float, content: Any) -> None:\n        \"\"\"\n        Add an entry to the internal memory.\n\n        Args:\n            score (float): The score or fitness value associated with the entry.\n            content (Any): The content of the entry.\n\n        Returns:\n            None\n        \"\"\"\n        random_key: str = str(uuid.uuid4())\n        self.data[random_key] = {\"score\": score, \"content\": content}\n\n        # keep only the best n entries\n        sorted_data: List[Tuple[str, Dict[str, Any]]] = sorted(\n            self.data.items(),\n            key=lambda x: x[1][\"score\"],\n            reverse=True,\n        )\n        self.data = dict(sorted_data[: self.n_entries])\n\n    def get_top_n(self, n: int) -> List[Tuple[str, Dict[str, Any]]]:\n        \"\"\"\n        Get the top n entries from the internal memory.\n\n        Args:\n            n (int): The number of top entries to retrieve.\n\n        Returns:\n            List[Tuple[str, Dict[str, Any]]]: A list of tuples containing the random keys and corresponding entry data.\n        \"\"\"\n        sorted_data: List[Tuple[str, Dict[str, Any]]] = sorted(\n            self.data.items(),\n            key=lambda x: x[1][\"score\"],\n            reverse=True,\n        )\n        return sorted_data[:n]\n\n    def len(self) -> int:\n        \"\"\"\n        Get the number of entries in the internal memory.\n\n        Returns:\n            int: The number of entries in the internal memory.\n        \"\"\"\n        return len(self.data)\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:37:56"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the DictInternalMemory class\n\n# Import necessary libraries\nimport random\n\n# Create an instance of the DictInternalMemory class with a limit of 5 entries\nmemory = DictInternalMemory(n_entries=5)\n\n# Function to simulate adding entries to the internal memory\ndef add_entries_to_memory(num_entries):\n    for _ in range(num_entries):\n        score = random.uniform(0, 100)  # Generate a random score between 0 and 100\n        content = f\"Entry with score {score}\"  # Create a content string\n        memory.add(score=score, entry=content)  # Add the entry to memory\n\n# Add 10 entries to the internal memory\nadd_entries_to_memory(10)\n\n# Retrieve and print the top 5 entries from the internal memory\ntop_entries = memory.get_top_n(n=5)\nprint(\"Top 5 entries in internal memory:\")\nfor key, entry in top_entries:\n    print(f\"Key: {key}, Score: {entry['score']}, Content: {entry['content']}\")\n\n# Print the total number of entries currently in memory\nprint(f\"\\nTotal entries in memory: {memory.len()}\")\n\n# Add more entries to see how the memory limits the number of stored entries\nadd_entries_to_memory(10)\n\n# Retrieve and print the updated top 5 entries from the internal memory\nupdated_top_entries = memory.get_top_n(n=5)\nprint(\"\\nUpdated Top 5 entries in internal memory after adding more entries:\")\nfor key, entry in updated_top_entries:\n    print(f\"Key: {key}, Score: {entry['score']}, Content: {entry['content']}\")\n\n# Print the total number of entries currently in memory after updates\nprint(f\"\\nTotal entries in memory after updates: {memory.len()}\")\n```",
                "timestamp": "2024-08-28 16:38:02"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom pydantic import BaseModel\n\n\nclass ActionSubtaskEntry(BaseModel):\n    \"\"\"Used to store ActionSubtask data to preserve TaskMemory pointers and context in the form of thought and action.\n\n    Attributes:\n    thought: CoT thought string from the LLM.\n    action: ReAct action JSON string from the LLM.\n    answer: tool-generated and memory-processed response from Griptape.\n    \"\"\"\n\n    thought: str\n    action: str\n    answer: str\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:38:02"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the ActionSubtaskEntry class\n\n# Import the ActionSubtaskEntry model\nfrom pydantic import BaseModel\n\n# Create an instance of the ActionSubtaskEntry class\ndef main():\n    # Create a new action subtask entry with thought, action, and answer attributes\n    action_entry = ActionSubtaskEntry(\n        thought=\"I need to calculate the sum of two numbers.\",\n        action='{\"tool\": \"calculator\", \"operation\": \"add\", \"numbers\": [5, 3]}',\n        answer=\"The sum of 5 and 3 is 8.\"\n    )\n\n    # Print the attributes of the action entry\n    print(\"Thought:\", action_entry.thought)\n    print(\"Action:\", action_entry.action)\n    print(\"Answer:\", action_entry.answer)\n\n    # Validate the instance and print its data as a dictionary\n    entry_data = action_entry.dict()\n    print(\"Entry Data as Dictionary:\", entry_data)\n\n# Entry point of the script\nif __name__ == \"__main__\":\n    main()\n```",
                "timestamp": "2024-08-28 16:38:06"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom abc import ABC\nfrom loguru import logger\n\n\nclass BaseVectorDatabase(ABC):\n    \"\"\"\n    Abstract base class for a database.\n\n    This class defines the interface for interacting with a database.\n    Subclasses must implement the abstract methods to provide the\n    specific implementation details for connecting to a database,\n    executing queries, and performing CRUD operations.\n\n    \"\"\"\n\n    def connect(self):\n        \"\"\"\n        Connect to the database.\n\n        This method establishes a connection to the database.\n\n        \"\"\"\n\n    def close(self):\n        \"\"\"\n        Close the database connection.\n\n        This method closes the connection to the database.\n\n        \"\"\"\n\n    def query(self, query: str):\n        \"\"\"\n        Execute a database query.\n\n        This method executes the given query on the database.\n\n        Parameters:\n            query (str): The query to be executed.\n\n        \"\"\"\n\n    def fetch_all(self):\n        \"\"\"\n        Fetch all rows from the result set.\n\n        This method retrieves all rows from the result set of a query.\n\n        Returns:\n            list: A list of dictionaries representing the rows.\n\n        \"\"\"\n\n    def fetch_one(self):\n        \"\"\"\n        Fetch one row from the result set.\n\n        This method retrieves one row from the result set of a query.\n\n        Returns:\n            dict: A dictionary representing the row.\n\n        \"\"\"\n\n    def add(self, doc: str):\n        \"\"\"\n        Add a new record to the database.\n\n        This method adds a new record to the specified table in the database.\n\n        Parameters:\n            table (str): The name of the table.\n            data (dict): A dictionary representing the data to be added.\n\n        \"\"\"\n\n    def get(self, query: str):\n        \"\"\"\n        Get a record from the database.\n\n        This method retrieves a record from the specified table in the database based on the given ID.\n\n        Parameters:\n            table (str): The name of the table.\n            id (int): The ID of the record to be retrieved.\n\n        Returns:\n            dict: A dictionary representing the retrieved record.\n\n        \"\"\"\n\n    def update(self, doc):\n        \"\"\"\n        Update a record in the database.\n\n        This method updates a record in the specified table in the database based on the given ID.\n\n        Parameters:\n            table (str): The name of the table.\n            id (int): The ID of the record to be updated.\n            data (dict): A dictionary representing the updated data.\n\n        \"\"\"\n\n    def delete(self, message):\n        \"\"\"\n        Delete a record from the database.\n\n        This method deletes a record from the specified table in the database based on the given ID.\n\n        Parameters:\n            table (str): The name of the table.\n            id (int): The ID of the record to be deleted.\n\n        \"\"\"\n\n    def print_all(self):\n        \"\"\"\n        Print all records in the database.\n\n        This method prints all records in the specified table in the database.\n\n        \"\"\"\n        pass\n\n    def log_query(self, query: str = None):\n        \"\"\"\n        Log the query.\n\n        This method logs the query that was executed on the database.\n\n        Parameters:\n            query (str): The query that was executed.\n\n        \"\"\"\n        logger.info(f\"Query: {query}\")\n\n    def log_retrieved_data(self, data: list = None):\n        \"\"\"\n        Log the retrieved data.\n\n        This method logs the data that was retrieved from the database.\n\n        Parameters:\n            data (dict): The data that was retrieved.\n\n        \"\"\"\n        for d in data:\n            logger.info(f\"Retrieved Data: {d}\")\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:38:06"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the BaseVectorDatabase class\n\n# First, we need to create a concrete implementation of the BaseVectorDatabase class.\n# Let's create a simple in-memory vector database for demonstration purposes.\n\nfrom loguru import logger\n\nclass InMemoryVectorDatabase(BaseVectorDatabase):\n    \"\"\"Concrete implementation of the BaseVectorDatabase using an in-memory dictionary.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty in-memory database.\"\"\"\n        self.database = {}\n        self.counter = 0  # To simulate auto-incrementing IDs\n\n    def connect(self):\n        \"\"\"Establish a connection to the in-memory database (no action needed here).\"\"\"\n        logger.info(\"Connected to in-memory vector database.\")\n\n    def close(self):\n        \"\"\"Close the connection to the database (no action needed here).\"\"\"\n        logger.info(\"Closed connection to in-memory vector database.\")\n\n    def query(self, query: str):\n        \"\"\"Simulate querying the database by returning stored entries that match the query.\"\"\"\n        logger.info(f\"Executing query: {query}\")\n        # For demonstration, we'll just return all entries since we don't have actual query parsing\n        return self.fetch_all()\n\n    def fetch_all(self):\n        \"\"\"Fetch all records from the in-memory database.\"\"\"\n        logger.info(\"Fetching all records from the database.\")\n        return list(self.database.values())\n\n    def fetch_one(self):\n        \"\"\"Fetch one record from the in-memory database (not implemented for simplicity).\"\"\"\n        logger.warning(\"fetch_one not implemented in in-memory database.\")\n\n    def add(self, doc: str):\n        \"\"\"Add a new document to the in-memory database.\"\"\"\n        self.counter += 1\n        self.database[self.counter] = {\"id\": self.counter, \"doc\": doc}\n        logger.info(f\"Added document with ID {self.counter}.\")\n\n    def get(self, query: str):\n        \"\"\"Retrieve a record based on the query (ID in this case).\"\"\"\n        doc_id = int(query)\n        logger.info(f\"Retrieving document with ID: {doc_id}\")\n        return self.database.get(doc_id)\n\n    def update(self, doc):\n        \"\"\"Update a record in the in-memory database.\"\"\"\n        doc_id = doc.get(\"id\")\n        if doc_id in self.database:\n            self.database[doc_id] = doc\n            logger.info(f\"Updated document with ID {doc_id}.\")\n        else:\n            logger.warning(f\"Document with ID {doc_id} not found for update.\")\n\n    def delete(self, message):\n        \"\"\"Delete a record from the in-memory database based on the ID.\"\"\"\n        doc_id = int(message)\n        if doc_id in self.database:\n            del self.database[doc_id]\n            logger.info(f\"Deleted document with ID {doc_id}.\")\n        else:\n            logger.warning(f\"Document with ID {doc_id} not found for deletion.\")\n\n    def print_all(self):\n        \"\"\"Print all records in the database.\"\"\"\n        for entry in self.database.values():\n            print(entry)\n\n# Example usage of the InMemoryVectorDatabase class\ndb = InMemoryVectorDatabase()\ndb.connect()\n\n# Add some documents to the database\ndb.add(\"This is the first document.\")\ndb.add(\"This is the second document.\")\ndb.add(\"This is the third document.\")\n\n# Query the database to fetch all entries\nall_entries = db.fetch_all()\nprint(\"All entries in the database:\")\nfor entry in all_entries:\n    print(entry)\n\n# Retrieve a specific document by ID\ndoc_id_to_retrieve = 2\nretrieved_doc = db.get(str(doc_id_to_retrieve))\nprint(f\"\\nRetrieved document with ID {doc_id_to_retrieve}: {retrieved_doc}\")\n\n# Update a document\ndb.update({\"id\": 2, \"doc\": \"This is the updated second document.\"})\n\n# Retrieve the updated document\nupdated_doc = db.get(\"2\")\nprint(f\"\\nUpdated document with ID 2: {updated_doc}\")\n\n# Delete a document\ndb.delete(\"1\")\n\n# Print all entries after deletion\nprint(\"\\nEntries after deletion:\")\ndb.print_all()\n\n# Close the database connection\ndb.close()\n```",
                "timestamp": "2024-08-28 16:38:16"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom typing import Any, Callable, Dict, List, Optional\n\nimport pinecone\nfrom loguru import logger\nfrom sentence_transformers import SentenceTransformer\nfrom swarms_memory.vector_dbs.base_vectordb import BaseVectorDatabase\n\n\nclass PineconeMemory(BaseVectorDatabase):\n    \"\"\"\n    A highly customizable wrapper class for Pinecone-based Retrieval-Augmented Generation (RAG) system.\n\n    This class provides methods to add documents to the Pinecone index and query the index\n    for similar documents. It allows for custom embedding models, preprocessing functions,\n    and other customizations.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        environment: str,\n        index_name: str,\n        dimension: int = 768,\n        embedding_model: Optional[Any] = None,\n        embedding_function: Optional[\n            Callable[[str], List[float]]\n        ] = None,\n        preprocess_function: Optional[Callable[[str], str]] = None,\n        postprocess_function: Optional[\n            Callable[[List[Dict[str, Any]]], List[Dict[str, Any]]]\n        ] = None,\n        metric: str = \"cosine\",\n        pod_type: str = \"p1\",\n        namespace: str = \"\",\n        logger_config: Optional[Dict[str, Any]] = None,\n    ):\n        \"\"\"\n        Initialize the PineconeMemory.\n\n        Args:\n            api_key (str): Pinecone API key.\n            environment (str): Pinecone environment.\n            index_name (str): Name of the Pinecone index to use.\n            dimension (int): Dimension of the document embeddings. Defaults to 768.\n            embedding_model (Optional[Any]): Custom embedding model. Defaults to None.\n            embedding_function (Optional[Callable]): Custom embedding function. Defaults to None.\n            preprocess_function (Optional[Callable]): Custom preprocessing function. Defaults to None.\n            postprocess_function (Optional[Callable]): Custom postprocessing function. Defaults to None.\n            metric (str): Distance metric for Pinecone index. Defaults to 'cosine'.\n            pod_type (str): Pinecone pod type. Defaults to 'p1'.\n            namespace (str): Pinecone namespace. Defaults to ''.\n            logger_config (Optional[Dict]): Configuration for the logger. Defaults to None.\n        \"\"\"\n        super().__init__()\n        self._setup_logger(logger_config)\n        logger.info(\"Initializing PineconeMemory\")\n\n        pinecone.init(api_key=api_key, environment=environment)\n\n        if index_name not in pinecone.list_indexes():\n            logger.info(f\"Creating new Pinecone index: {index_name}\")\n            pinecone.create_index(\n                index_name,\n                dimension=dimension,\n                metric=metric,\n                pod_type=pod_type,\n            )\n\n        self.index = pinecone.Index(index_name)\n        self.namespace = namespace\n\n        self.embedding_model = embedding_model or SentenceTransformer(\n            \"all-MiniLM-L6-v2\"\n        )\n        self.embedding_function = (\n            embedding_function or self._default_embedding_function\n        )\n        self.preprocess_function = (\n            preprocess_function or self._default_preprocess_function\n        )\n        self.postprocess_function = (\n            postprocess_function or self._default_postprocess_function\n        )\n\n        logger.info(\"PineconeMemory initialized successfully\")\n\n    def _setup_logger(self, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Set up the logger with the given configuration.\"\"\"\n        default_config = {\n            \"handlers\": [\n                {\"sink\": \"rag_wrapper.log\", \"rotation\": \"500 MB\"},\n                {\"sink\": lambda msg: print(msg, end=\"\")},\n            ],\n        }\n        logger.configure(**(config or default_config))\n\n    def _default_embedding_function(self, text: str) -> List[float]:\n        \"\"\"Default embedding function using the SentenceTransformer model.\"\"\"\n        return self.embedding_model.encode(text).tolist()\n\n    def _default_preprocess_function(self, text: str) -> str:\n        \"\"\"Default preprocessing function.\"\"\"\n        return text.strip()\n\n    def _default_postprocess_function(\n        self, results: List[Dict[str, Any]]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Default postprocessing function.\"\"\"\n        return results\n\n    def add(\n        self, doc: str, metadata: Optional[Dict[str, Any]] = None\n    ) -> None:\n        \"\"\"\n        Add a document to the Pinecone index.\n\n        Args:\n            doc (str): The document to be added.\n            metadata (Optional[Dict[str, Any]]): Additional metadata for the document.\n\n        Returns:\n            None\n        \"\"\"\n        logger.info(f\"Adding document: {doc[:50]}...\")\n        processed_doc = self.preprocess_function(doc)\n        embedding = self.embedding_function(processed_doc)\n        id = str(abs(hash(doc)))\n        metadata = metadata or {}\n        metadata[\"text\"] = processed_doc\n        self.index.upsert(\n            vectors=[(id, embedding, metadata)],\n            namespace=self.namespace,\n        )\n        logger.success(f\"Document added successfully with ID: {id}\")\n\n    def query(\n        self,\n        query: str,\n        top_k: int = 5,\n        filter: Optional[Dict[str, Any]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Query the Pinecone index for similar documents.\n\n        Args:\n            query (str): The query string.\n            top_k (int): The number of top results to return. Defaults to 5.\n            filter (Optional[Dict[str, Any]]): Metadata filter for the query.\n\n        Returns:\n            List[Dict[str, Any]]: A list of dictionaries containing the top_k most similar documents.\n        \"\"\"\n        logger.info(f\"Querying with: {query}\")\n        processed_query = self.preprocess_function(query)\n        query_embedding = self.embedding_function(processed_query)\n        results = self.index.query(\n            vector=query_embedding,\n            top_k=top_k,\n            include_metadata=True,\n            namespace=self.namespace,\n            filter=filter,\n        )\n\n        formatted_results = []\n        for match in results.matches:\n            formatted_results.append(\n                {\n                    \"id\": match.id,\n                    \"score\": match.score,\n                    \"metadata\": match.metadata,\n                }\n            )\n\n        processed_results = self.postprocess_function(\n            formatted_results\n        )\n        logger.success(\n            f\"Query completed. Found {len(processed_results)} results.\"\n        )\n        return processed_results\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:38:16"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the PineconeMemory class\n\n# Import necessary libraries\nimport os\nfrom typing import Dict, Any\n\n# Define your Pinecone API key and environment\nAPI_KEY = os.getenv(\"PINECONE_API_KEY\")  # Make sure to set your Pinecone API key in the environment\nENVIRONMENT = \"us-west1-gcp\"  # Example environment\nINDEX_NAME = \"my-pinecone-index\"  # Name of the Pinecone index to use\n\n# Create an instance of the PineconeMemory class\npinecone_memory = PineconeMemory(\n    api_key=API_KEY,\n    environment=ENVIRONMENT,\n    index_name=INDEX_NAME,\n    dimension=768,  # Dimension of the embeddings\n)\n\n# Function to add documents to the Pinecone index\ndef add_documents():\n    \"\"\"Add sample documents to the Pinecone index.\"\"\"\n    documents = [\n        \"This is the first document about machine learning.\",\n        \"This document discusses deep learning techniques.\",\n        \"Here we talk about natural language processing.\",\n        \"This is another document related to artificial intelligence.\",\n        \"This document covers supervised and unsupervised learning.\"\n    ]\n    \n    for doc in documents:\n        # Adding documents to the Pinecone index with optional metadata\n        pinecone_memory.add(doc, metadata={\"source\": \"example\"})\n\n# Function to query documents from the Pinecone index\ndef query_documents(query: str):\n    \"\"\"Query the Pinecone index for similar documents.\"\"\"\n    results = pinecone_memory.query(query, top_k=3)  # Retrieve the top 3 similar documents\n    print(\"\\nQuery Results:\")\n    for result in results:\n        print(f\"ID: {result['id']}, Score: {result['score']}, Metadata: {result['metadata']}\")\n\n# Adding documents to the Pinecone index\nadd_documents()\n\n# Querying the Pinecone index\nquery_documents(\"Tell me about machine learning techniques.\")\n\n# Close the Pinecone index (if needed, cleanup)\n# Note: Pinecone does not require a close method as it is a managed service.\n```",
                "timestamp": "2024-08-28 16:38:22"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nimport os\nimport uuid\nfrom typing import Optional\n\nimport chromadb\nfrom dotenv import load_dotenv\nfrom loguru import logger\nfrom swarms_memory.vector_dbs.base_vectordb import BaseVectorDatabase\nfrom swarms.utils.data_to_text import data_to_text\n\n# Load environment variables\nload_dotenv()\n\n\n# Results storage using local ChromaDB\nclass ChromaDB(BaseVectorDatabase):\n    \"\"\"\n\n    ChromaDB database\n\n    Args:\n        metric (str): The similarity metric to use.\n        output (str): The name of the collection to store the results in.\n        limit_tokens (int, optional): The maximum number of tokens to use for the query. Defaults to 1000.\n        n_results (int, optional): The number of results to retrieve. Defaults to 2.\n\n    Methods:\n        add: _description_\n        query: _description_\n\n    Examples:\n        >>> chromadb = ChromaDB(\n        >>>     metric=\"cosine\",\n        >>>     output=\"results\",\n        >>>     llm=\"gpt3\",\n        >>>     openai_api_key=OPENAI_API_KEY,\n        >>> )\n        >>> chromadb.add(task, result, result_id)\n    \"\"\"\n\n    def __init__(\n        self,\n        metric: str = \"cosine\",\n        output_dir: str = \"swarms\",\n        limit_tokens: Optional[int] = 1000,\n        n_results: int = 1,\n        docs_folder: str = None,\n        verbose: bool = False,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(*args, **kwargs)\n        self.metric = metric\n        self.output_dir = output_dir\n        self.limit_tokens = limit_tokens\n        self.n_results = n_results\n        self.docs_folder = docs_folder\n        self.verbose = verbose\n\n        # Create Chroma collection\n        chroma_persist_dir = \"chroma\"\n        chroma_client = chromadb.PersistentClient(\n            settings=chromadb.config.Settings(\n                persist_directory=chroma_persist_dir,\n            ),\n            *args,\n            **kwargs,\n        )\n\n        # Create ChromaDB client\n        self.client = chromadb.Client()\n\n        # Create Chroma collection\n        self.collection = chroma_client.get_or_create_collection(\n            name=output_dir,\n            metadata={\"hnsw:space\": metric},\n            *args,\n            **kwargs,\n        )\n        logger.info(\n            \"ChromaDB collection created:\"\n            f\" {self.collection.name} with metric: {self.metric} and\"\n            f\" output directory: {self.output_dir}\"\n        )\n\n        # If docs\n        if docs_folder:\n            logger.info(f\"Traversing directory: {docs_folder}\")\n            self.traverse_directory()\n\n    def add(\n        self,\n        document: str,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Add a document to the ChromaDB collection.\n\n        Args:\n            document (str): The document to be added.\n            condition (bool, optional): The condition to check before adding the document. Defaults to True.\n\n        Returns:\n            str: The ID of the added document.\n        \"\"\"\n        try:\n            doc_id = str(uuid.uuid4())\n            self.collection.add(\n                ids=[doc_id],\n                documents=[document],\n                *args,\n                **kwargs,\n            )\n            print(\"-----------------\")\n            print(\"Document added successfully\")\n            print(\"-----------------\")\n            return doc_id\n        except Exception as e:\n            raise Exception(f\"Failed to add document: {str(e)}\")\n\n    def query(\n        self,\n        query_text: str,\n        *args,\n        **kwargs,\n    ) -> str:\n        \"\"\"\n        Query documents from the ChromaDB collection.\n\n        Args:\n            query (str): The query string.\n            n_docs (int, optional): The number of documents to retrieve. Defaults to 1.\n\n        Returns:\n            dict: The retrieved documents.\n        \"\"\"\n        try:\n            logger.info(f\"Querying documents for: {query_text}\")\n            docs = self.collection.query(\n                query_texts=[query_text],\n                n_results=self.n_results,\n                *args,\n                **kwargs,\n            )[\"documents\"]\n\n            # Convert into a string\n            out = \"\"\n            for doc in docs:\n                out += f\"{doc}\\n\"\n\n            # Display the retrieved document\n            logger.info(f\"Query: {query_text}\")\n            logger.info(f\"Retrieved Document: {out}\")\n            return out\n\n        except Exception as e:\n            raise Exception(f\"Failed to query documents: {str(e)}\")\n\n    def traverse_directory(\n        self, docs_folder: str = None, *args, **kwargs\n    ):\n        \"\"\"\n        Traverse through every file in the given directory and its subdirectories,\n        and return the paths of all files.\n        Parameters:\n        - directory_name (str): The name of the directory to traverse.\n        Returns:\n        - list: A list of paths to each file in the directory and its subdirectories.\n        \"\"\"\n        try:\n            logger.info(f\"Traversing directory: {self.docs_folder}\")\n            added_to_db = False\n            allowed_extensions = [\n                \"txt\",\n                \"pdf\",\n                \"docx\",\n                \"doc\",\n                \"md\",\n                \"yaml\",\n                \"json\",\n                \"csv\",\n                \"tsv\",\n                \"xls\",\n                \"xlsx\",\n                \"xml\",\n                \"yml\",\n            ]\n\n            for root, dirs, files in os.walk(self.docs_folder):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    _, ext = os.path.splitext(file_path)\n                    if ext.lower() in allowed_extensions:\n                        data = data_to_text(file_path)\n                        added_to_db = self.add(str(data))\n                        print(f\"{file_path} added to Database\")\n                    else:\n                        print(\n                            f\"Skipped {file_path} due to unsupported file extension\"\n                        )\n\n            return added_to_db\n\n        except Exception as error:\n            logger.error(\n                f\"Failed to traverse directory: {str(error)}\"\n            )\n            raise error\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:38:22"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the ChromaDB class\n\n# Import necessary libraries\nimport os\nfrom swarms_memory.vector_dbs.chroma_db import ChromaDB\n\n# Define the folder where documents are stored (optional)\ndocs_folder = \"path/to/docs\"  # Replace with your actual folder path\n\n# Create an instance of the ChromaDB class\nchroma_db = ChromaDB(\n    metric=\"cosine\",  # Similarity metric to use\n    output_dir=\"results\",  # Name of the collection to store results\n    docs_folder=docs_folder,  # Optional folder to traverse for documents\n)\n\n# Function to add a document to the ChromaDB\ndef add_document(document: str):\n    \"\"\"Add a sample document to the ChromaDB.\"\"\"\n    doc_id = chroma_db.add(document)  # Add the document and get its ID\n    print(f\"Added document with ID: {doc_id}\")\n\n# Function to query documents from ChromaDB\ndef query_documents(query_text: str):\n    \"\"\"Query documents from the ChromaDB.\"\"\"\n    results = chroma_db.query(query_text)  # Query the database\n    print(\"Query Results:\\n\", results)  # Print the retrieved documents\n\n# Example document to add\nsample_document = \"This is a sample document containing information about machine learning.\"\nadd_document(sample_document)  # Adding the sample document\n\n# Querying the database for similar documents\nquery_text = \"information about machine learning\"\nquery_documents(query_text)  # Perform the query\n\n# If you want to traverse a directory and add all supported files to the ChromaDB\nif docs_folder:\n    chroma_db.traverse_directory(docs_folder)  # Traverse and add documents from the specified folder\n```",
                "timestamp": "2024-08-28 16:38:27"
            },
            {
                "role": "swarms_corp",
                "content": "Generate a usage example for the following Python code:\n\nfrom typing import List, Dict, Any, Callable, Optional\nimport faiss\nimport numpy as np\nfrom loguru import logger\nfrom sentence_transformers import SentenceTransformer\nfrom swarms_memory.vector_dbs.base_vectordb import BaseVectorDatabase\n\n\nclass FAISSDB(BaseVectorDatabase):\n    \"\"\"\n    A highly customizable wrapper class for FAISS-based Retrieval-Augmented Generation (RAG) system.\n\n    This class provides methods to add documents to the FAISS index and query the index\n    for similar documents. It allows for custom embedding models, preprocessing functions,\n    and other customizations.\n    \"\"\"\n\n    def __init__(\n        self,\n        dimension: int = 768,\n        index_type: str = \"Flat\",\n        embedding_model: Optional[Any] = None,\n        embedding_function: Optional[\n            Callable[[str], List[float]]\n        ] = None,\n        preprocess_function: Optional[Callable[[str], str]] = None,\n        postprocess_function: Optional[\n            Callable[[List[Dict[str, Any]]], List[Dict[str, Any]]]\n        ] = None,\n        metric: str = \"cosine\",\n        logger_config: Optional[Dict[str, Any]] = None,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize the FAISSDB.\n\n        Args:\n            dimension (int): Dimension of the document embeddings. Defaults to 768.\n            index_type (str): Type of FAISS index to use. Defaults to 'Flat'.\n            embedding_model (Optional[Any]): Custom embedding model. Defaults to None.\n            embedding_function (Optional[Callable]): Custom embedding function. Defaults to None.\n            preprocess_function (Optional[Callable]): Custom preprocessing function. Defaults to None.\n            postprocess_function (Optional[Callable]): Custom postprocessing function. Defaults to None.\n            metric (str): Distance metric for FAISS index. Defaults to 'cosine'.\n            logger_config (Optional[Dict]): Configuration for the logger. Defaults to None.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self._setup_logger(logger_config)\n        logger.info(\"Initializing FAISSDB\")\n\n        self.dimension = dimension\n        self.index = self._create_index(index_type, metric)\n        self.documents = []\n\n        self.embedding_model = embedding_model or SentenceTransformer(\n            \"all-MiniLM-L6-v2\"\n        )\n        self.embedding_function = (\n            embedding_function or self._default_embedding_function\n        )\n        self.preprocess_function = (\n            preprocess_function or self._default_preprocess_function\n        )\n        self.postprocess_function = (\n            postprocess_function or self._default_postprocess_function\n        )\n\n        logger.info(\"FAISSDB initialized successfully\")\n\n    def _setup_logger(self, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Set up the logger with the given configuration.\"\"\"\n        default_config = {\n            \"handlers\": [\n                {\n                    \"sink\": \"faiss_rag_wrapper.log\",\n                    \"rotation\": \"500 MB\",\n                },\n                {\"sink\": lambda msg: print(msg, end=\"\")},\n            ],\n        }\n        logger.configure(**(config or default_config))\n\n    def _create_index(self, index_type: str, metric: str):\n        \"\"\"Create and return a FAISS index based on the specified type and metric.\"\"\"\n        if metric == \"cosine\":\n            index = faiss.IndexFlatIP(self.dimension)\n        elif metric == \"l2\":\n            index = faiss.IndexFlatL2(self.dimension)\n        else:\n            raise ValueError(f\"Unsupported metric: {metric}\")\n\n        if index_type == \"Flat\":\n            return index\n        elif index_type == \"IVF\":\n            nlist = 100  # number of clusters\n            quantizer = faiss.IndexFlatL2(self.dimension)\n            index = faiss.IndexIVFFlat(\n                quantizer, self.dimension, nlist\n            )\n        else:\n            raise ValueError(f\"Unsupported index type: {index_type}\")\n\n        return index\n\n    def _default_embedding_function(self, text: str) -> List[float]:\n        \"\"\"Default embedding function using the SentenceTransformer model.\"\"\"\n        return self.embedding_model.encode(text).tolist()\n\n    def _default_preprocess_function(self, text: str) -> str:\n        \"\"\"Default preprocessing function.\"\"\"\n        return text.strip()\n\n    def _default_postprocess_function(\n        self, results: List[Dict[str, Any]]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Default postprocessing function.\"\"\"\n        return results\n\n    def add(\n        self, doc: str, metadata: Optional[Dict[str, Any]] = None\n    ) -> None:\n        \"\"\"\n        Add a document to the FAISS index.\n\n        Args:\n            doc (str): The document to be added.\n            metadata (Optional[Dict[str, Any]]): Additional metadata for the document.\n\n        Returns:\n            None\n        \"\"\"\n        logger.info(f\"Adding document: {doc[:50]}...\")\n        processed_doc = self.preprocess_function(doc)\n        embedding = self.embedding_function(processed_doc)\n\n        self.index.add(np.array([embedding], dtype=np.float32))\n        metadata = metadata or {}\n        metadata[\"text\"] = processed_doc\n        self.documents.append(metadata)\n\n        logger.success(\n            f\"Document added successfully. Total documents: {len(self.documents)}\"\n        )\n\n    def query(\n        self, query: str, top_k: int = 5\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Query the FAISS index for similar documents.\n\n        Args:\n            query (str): The query string.\n            top_k (int): The number of top results to return. Defaults to 5.\n\n        Returns:\n            List[Dict[str, Any]]: A list of dictionaries containing the top_k most similar documents.\n        \"\"\"\n        logger.info(f\"Querying with: {query}\")\n        processed_query = self.preprocess_function(query)\n        query_embedding = self.embedding_function(processed_query)\n\n        distances, indices = self.index.search(\n            np.array([query_embedding], dtype=np.float32), top_k\n        )\n\n        results = []\n        for i, (distance, idx) in enumerate(\n            zip(distances[0], indices[0])\n        ):\n            if idx != -1:  # FAISS uses -1 for empty slots\n                result = {\n                    \"id\": idx,\n                    \"score\": 1\n                    - distance,  # Convert distance to similarity score\n                    \"metadata\": self.documents[idx],\n                }\n                results.append(result)\n\n        processed_results = self.postprocess_function(results)\n        logger.success(\n            f\"Query completed. Found {len(processed_results)} results.\"\n        )\n        return processed_results\n\n\n# # Example usage\n# if __name__ == \"__main__\":\n#     from transformers import AutoTokenizer, AutoModel\n#     import torch\n\n#     # Custom embedding function using a HuggingFace model\n#     def custom_embedding_function(text: str) -> List[float]:\n#         tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n#         model = AutoModel.from_pretrained(\"bert-base-uncased\")\n#         inputs = tokenizer(\n#             text,\n#             return_tensors=\"pt\",\n#             padding=True,\n#             truncation=True,\n#             max_length=512,\n#         )\n#         with torch.no_grad():\n#             outputs = model(**inputs)\n#         embeddings = (\n#             outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n#         )\n#         return embeddings\n\n#     # Custom preprocessing function\n#     def custom_preprocess(text: str) -> str:\n#         return text.lower().strip()\n\n#     # Custom postprocessing function\n#     def custom_postprocess(\n#         results: List[Dict[str, Any]],\n#     ) -> List[Dict[str, Any]]:\n#         for result in results:\n#             result[\"custom_score\"] = (\n#                 result[\"score\"] * 2\n#             )  # Example modification\n#         return results\n\n#     # Initialize the wrapper with custom functions\n#     wrapper = FAISSDB(\n#         dimension=768,\n#         index_type=\"Flat\",\n#         embedding_function=custom_embedding_function,\n#         preprocess_function=custom_preprocess,\n#         postprocess_function=custom_postprocess,\n#         metric=\"cosine\",\n#         logger_config={\n#             \"handlers\": [\n#                 {\n#                     \"sink\": \"custom_faiss_rag_wrapper.log\",\n#                     \"rotation\": \"1 GB\",\n#                 },\n#                 {\n#                     \"sink\": lambda msg: print(\n#                         f\"Custom log: {msg}\", end=\"\"\n#                     )\n#                 },\n#             ],\n#         },\n#     )\n\n#     # Adding documents\n#     wrapper.add(\n#         \"This is a sample document about artificial intelligence.\",\n#         {\"category\": \"AI\"},\n#     )\n#     wrapper.add(\n#         \"Python is a popular programming language for data science.\",\n#         {\"category\": \"Programming\"},\n#     )\n\n#     # Querying\n#     results = wrapper.query(\"What is AI?\")\n#     for result in results:\n#         print(\n#             f\"Score: {result['score']}, Custom Score: {result['custom_score']}, Text: {result['metadata']['text']}\"\n#         )\n\n\nProvide detailed comments.",
                "timestamp": "2024-08-28 16:38:27"
            },
            {
                "role": "ExampleCreator",
                "content": "```python\n# Example usage of the FAISSDB class\n\n# Import necessary libraries\nfrom typing import List, Dict\nfrom sentence_transformers import SentenceTransformer\n\n# Create an instance of the FAISSDB class\nfaiss_db = FAISSDB(\n    dimension=768,  # Dimension of the embeddings\n    index_type=\"Flat\",  # Type of FAISS index to use\n)\n\n# Function to add documents to the FAISS index\ndef add_documents():\n    \"\"\"Add sample documents to the FAISS index.\"\"\"\n    documents = [\n        \"This is the first document about machine learning.\",\n        \"This document discusses deep learning techniques.\",\n        \"Here we talk about natural language processing.\",\n        \"This is another document related to artificial intelligence.\",\n        \"This document covers supervised and unsupervised learning.\"\n    ]\n    \n    for doc in documents:\n        # Adding documents to the FAISS index with optional metadata\n        faiss_db.add(doc, metadata={\"source\": \"example\"})\n\n# Function to query documents from the FAISS index\ndef query_documents(query: str):\n    \"\"\"Query the FAISS index for similar documents.\"\"\"\n    results = faiss_db.query(query, top_k=3)  # Retrieve the top 3 similar documents\n    print(\"\\nQuery Results:\")\n    for result in results:\n        print(f\"ID: {result['id']}, Score: {result['score']}, Metadata: {result['metadata']}\")\n\n# Adding documents to the FAISS index\nadd_documents()\n\n# Querying the FAISS index\nquery_documents(\"Tell me about machine learning techniques.\")\n\n# The FAISS index will now contain the added documents, and the query will return the most relevant ones based on the embeddings.\n```",
                "timestamp": "2024-08-28 16:38:34"
            }
        ],
        "tokenizer": null,
        "context_length": 8192,
        "rules": null,
        "custom_rules_prompt": null,
        "user": "swarms_corp",
        "auto_save": true,
        "save_as_yaml": true,
        "save_as_json_bool": false
    }
}